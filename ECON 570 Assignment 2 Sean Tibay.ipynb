{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468275a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import graphviz as gr\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb2cc6",
   "metadata": {},
   "source": [
    "Note: For all sections, I interpretted the instructions regarding sample size as N=100 for the regressions within each simulation, and N=1000 for the number of Monte Carlo Simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a0af3",
   "metadata": {},
   "source": [
    "# Setting 1: Randomly Assigned Treatment\n",
    "\n",
    "Scenario A: Excludes Covariates\n",
    "\n",
    "Scenario B: Includes Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e8fdd",
   "metadata": {},
   "source": [
    "## Setting 1 DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63117498",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"D-treatment\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020663d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = .5\n",
    "b = 1.2\n",
    "c = 3\n",
    "d = 2.5\n",
    "n = 100\n",
    "\n",
    "dummy_a_estimates = []\n",
    "dummy_b_estimates = []\n",
    "\n",
    "RMSE_A_1 = []\n",
    "RMSE_B_1 = []\n",
    "\n",
    "\n",
    "for mc_replication in range(1000):\n",
    "    \n",
    "    #D is the randomly assigned treatment \n",
    "    D = np.random.randint(2, size=n)\n",
    "    Dvar = pd.DataFrame(D)\n",
    "    \n",
    "    #X1 and X2 are observed covariates that are omitted in alternate B.\n",
    "    X1 = np.random.uniform(0, 1, n)\n",
    "    X1var = pd.DataFrame(X1)\n",
    "    X2 = np.random.uniform(0, 15, n)\n",
    "    X2var = pd.DataFrame(X2)\n",
    "    \n",
    "    #Generated error dist.\n",
    "    e = np.random.normal(0, 10, n)\n",
    "\n",
    "    #Generated Observed Y values with observed parameters a,b,c,d\n",
    "    Y = a + b * X1 + c * X2 + d * D + e\n",
    "\n",
    "\n",
    "    X = pd.concat((X1var, X2var, Dvar), axis=1)\n",
    "    X.columns = ('X1', 'X2', 'D')\n",
    "    \n",
    "    #a represents model w/o x variables. b represents model including x variables.\n",
    "    mod_a = sm.OLS(Y,sm.add_constant(D))\n",
    "    mod_b = sm.OLS(Y, sm.add_constant(X))\n",
    "    res_a = mod_a.fit()\n",
    "    res_b = mod_b.fit()\n",
    "    Y_a_hat = res_a.params[0] + res_a.params[1] * D\n",
    "    Y_b_hat = res_b.params['const'] + res_b.params['X1'] * X1 + res_b.params['X2'] * X2 + res_b.params['D'] * D\n",
    "\n",
    "    #Calculating Coef. estimates, Biases, and RMSE\n",
    "    yi = pd.DataFrame(Y)\n",
    "    yha = pd.DataFrame(Y_a_hat)\n",
    "    yhb = pd.DataFrame(Y_b_hat)\n",
    "\n",
    "    SE_A = ((yi - yha) ** 2)\n",
    "    MSE_A = SE_A.mean()\n",
    "    RMSE_A = MSE_A ** 0.5\n",
    "\n",
    "    SE_B = ((yi - yhb) ** 2)\n",
    "    MSE_B = SE_B.mean()\n",
    "    RMSE_B = MSE_B ** 0.5\n",
    "\n",
    "\n",
    "    dummy_a_estimates += [res_a.params[1]]\n",
    "    dummy_b_estimates += [res_b.params['D']]\n",
    "\n",
    "    RMSE_A_1 += [RMSE_A]\n",
    "    RMSE_B_1 += [RMSE_B]\n",
    "\n",
    "#Final results --- avg. over 1000 Monte Carlo Simulations\n",
    "\n",
    "miua = round(np.mean(dummy_a_estimates),3)\n",
    "miub = round(np.mean(dummy_b_estimates),3)\n",
    "\n",
    "bias_a = round(miua - d,3)\n",
    "bias_b = round(miub - d,3)\n",
    "\n",
    "miu_ra = round(np.mean(RMSE_A_1),3)\n",
    "miu_rb = round(np.mean(RMSE_B_1),3)\n",
    "\n",
    "print(\"Treatment effect in situation A, not controlling for covariates is: \" + str(miua) + \" with a bias of \" + str(bias_a) + '.')\n",
    "print('\\n')\n",
    "print(\"Treatment effect in situation B, controlling for covariates is: \" + str(miub) + \" with a bias of \" + str(bias_b) + '.')\n",
    "print('\\n')\n",
    "print(\"As we see, omitting covariates will not change the effect of a randomly assigned treatment.\")\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print(\"RMSE in situation A, not controlling for covariates is: \" + str(miu_ra) + '.')\n",
    "print('\\n')\n",
    "print(\"RMSE in situation B, controlling for covariates is: \" + str(miu_rb) + '.')\n",
    "print('\\n')\n",
    "print(\"However, we see that omitting covariates will lead to higher RMSE.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4913db",
   "metadata": {},
   "source": [
    "A real life example of this first setting (Random assignment treatment) is a common example found in literature of a university or high school offering tutoring programs to students on a random/lottery basis. Since this selection is independent of any characteristics that may determine some outcome Y (test score, graduation, success...), the treatment effect of this program will be unbiased regardless of whether other variables are controlled for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3231ddb3",
   "metadata": {},
   "source": [
    "# Setting 2: Confounder\n",
    "    \n",
    "Scenario A: Excludes Confounder\n",
    "\n",
    "Scenario B: Includes Confounder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0aa7a6",
   "metadata": {},
   "source": [
    "## Confounder DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b21c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"Confounder: Z\", \"Y\")\n",
    "g.edge(\"Confounder: Z\", \"X1\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3.5\n",
    "b = 2.5\n",
    "c = 12\n",
    "n = 100\n",
    "\n",
    "coef_a_estimates = []\n",
    "coef_b_estimates = []\n",
    "\n",
    "RMSE_A_2 = []\n",
    "RMSE_B_2 = []\n",
    "\n",
    "for mc_replication in range(1000):\n",
    "\n",
    "    #Z variable is the confounder\n",
    "    Z = np.random.uniform(0, 200, n)\n",
    "    Zvar = pd.DataFrame(Z)\n",
    "\n",
    "    #randomly generating error distributions for confounder effect on X1 and Y\n",
    "    e1 = np.random.normal(0, 8, n)\n",
    "    e2 = np.random.normal(0, 8, n)\n",
    "    \n",
    "    #X1 is a function of Z\n",
    "    X1 = 5 + 3.5*Z + e1\n",
    "    X1var = pd.DataFrame(X1)\n",
    "    \n",
    "    #Y is a function of X1 and Z\n",
    "    Y = a + b * X1 + c * Z + e2\n",
    "\n",
    "    X = pd.concat((X1var, Zvar), axis=1)\n",
    "    X.columns = ('X1', 'Z')\n",
    "    \n",
    "    #Scenario A excludes the confounder Z, Scenario B includes the confounder Z\n",
    "    mod_a = sm.OLS(Y,sm.add_constant(X1))\n",
    "    mod_b = sm.OLS(Y, sm.add_constant(X))\n",
    "\n",
    "    res_a = mod_a.fit()\n",
    "    res_b = mod_b.fit()\n",
    "\n",
    "    Y_a_hat = res_a.params[0] + res_a.params[1] * X1\n",
    "    Y_b_hat = res_b.params['const'] + res_b.params['X1'] * X1 + res_b.params['Z'] * Z\n",
    "\n",
    "    #Calculating Coef. estimates, Biases, and RMSE\n",
    "    yi = pd.DataFrame(Y)\n",
    "    yha = pd.DataFrame(Y_a_hat)\n",
    "    yhb = pd.DataFrame(Y_b_hat)\n",
    "\n",
    "    SE_A = ((yi - yha) ** 2)\n",
    "    MSE_A = SE_A.mean()\n",
    "    RMSE_A = MSE_A ** 0.5\n",
    "\n",
    "    SE_B = ((yi - yhb) ** 2)\n",
    "    MSE_B = SE_B.mean()\n",
    "    RMSE_B = MSE_B ** 0.5\n",
    "\n",
    "\n",
    "    coef_a_estimates += [res_a.params[1]]\n",
    "    coef_b_estimates += [res_b.params['X1']]\n",
    "\n",
    "    RMSE_A_2 += [RMSE_A]\n",
    "    RMSE_B_2 += [RMSE_B]\n",
    "    \n",
    "\n",
    "#Final results --- avg. over 1000 Monte Carlo Simulations\n",
    "\n",
    "miua = round(np.mean(coef_a_estimates),3)\n",
    "miub = round(np.mean(coef_b_estimates),3)\n",
    "\n",
    "bias_a = round(miua - b,3)\n",
    "bias_b = round(miub - b,3)\n",
    "\n",
    "miu_ra = round(np.mean(RMSE_A_2),3)\n",
    "miu_rb = round(np.mean(RMSE_B_2),3)\n",
    "\n",
    "print(\"Effect of X1 in situation A, not controlling for confounder is: \" + str(miua) + \" with a bias of \" + str(bias_a) + '.')\n",
    "print('\\n')\n",
    "print(\"Effect of X1 in situation B, controlling for confounder is: \" + str(miub) + \" with a bias of \" + str(bias_b) + '.')\n",
    "print('\\n')\n",
    "print(\"As we see, omitting confounder will lead to bias in coefficient estimates.\")\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print(\"RMSE in situation A, not controlling for covariates is: \" + str(miu_ra) + '.')\n",
    "print('\\n')\n",
    "print(\"RMSE in situation B, controlling for covariates is: \" + str(miu_rb) + '.')\n",
    "print('\\n')\n",
    "print(\"We also see that omitting confounder will lead to higher RMSE.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962468b",
   "metadata": {},
   "source": [
    "A real life example of this second setting with a confounder is any example that has to deal with common omitted variable bias. For example, if we take salary or wages as the dependent variable, and we want to determine the effect of education on wages. A confounder, which may lead to bias if omitted could be ability or intelligence, which drives both education level/success and possibly wages/salary. In this case, if the confounder is omitted, the model will over-estimate the effect of education and lead to bias coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6eec08",
   "metadata": {},
   "source": [
    "# Setting 3: Selection Bias in Treatment\n",
    "Scenario A: Controls for the variable in between the path from cause to effect.\n",
    "\n",
    "Scenario B: Does not controls for the variable in between the path from cause to effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d876e",
   "metadata": {},
   "source": [
    "## Selection Bias DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"X\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"Y\", \"X\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 4\n",
    "b = 5.5\n",
    "c = 2\n",
    "d= 7.5\n",
    "n = 100\n",
    "\n",
    "treat_a_estimates = []\n",
    "treat_b_estimates = []\n",
    "\n",
    "RMSE_A_3 = []\n",
    "RMSE_B_3 = []\n",
    "\n",
    "for mc_replication in range(1000):\n",
    "\n",
    "    #Randomly generate X1 explanatory Variable\n",
    "    X1 = np.random.uniform(0, 60, n)\n",
    "    X1var = pd.DataFrame(X1)\n",
    "\n",
    "    #Randomly generate Treatment Variable with 70% probability of receiving treatment\n",
    "    treat = np.random.choice(2, size=n, p=[0.3, 0.7])\n",
    "    treatvar = pd.DataFrame(treat)\n",
    "    \n",
    "    #Generating Error Distribution\n",
    "    e1 = np.random.normal(0, 8, n)\n",
    "    e2 = np.random.normal(0, 8, n)\n",
    "\n",
    "    #Variable in between path\n",
    "    X2 = 4 + 3.5 * treat + e1\n",
    "    X2var = pd.DataFrame(X2)\n",
    "\n",
    "    #Generating Oberved Y variable\n",
    "    Y = a + b * X1 + c * X2 + d * treat + e2\n",
    "\n",
    "    #Scenario A includes path variable X2; Scenario B excludes path variable X2.\n",
    "    \n",
    "    Xa = pd.concat((X1var, X2var, treatvar), axis=1)\n",
    "    Xa.columns = ('X1', 'X2', 'treat')\n",
    "\n",
    "    Xb = pd.concat((X1var, treatvar), axis=1)\n",
    "    Xb.columns = ('X1', 'treat')\n",
    "\n",
    "    mod_a = sm.OLS(Y,sm.add_constant(Xa))\n",
    "    mod_b = sm.OLS(Y, sm.add_constant(Xb))\n",
    "\n",
    "    res_a = mod_a.fit()\n",
    "    res_b = mod_b.fit()\n",
    "\n",
    "    Y_a_hat = res_a.params['const'] + res_a.params['X1'] * X1 + res_a.params['X2'] * X2 + res_a.params['treat'] * treat\n",
    "    Y_b_hat = res_b.params['const'] + res_b.params['X1'] * X1 + res_b.params['treat'] * treat\n",
    "\n",
    "    #Calculating Coef. estimates, Biases, and RMSE\n",
    "    yi = pd.DataFrame(Y)\n",
    "    yha = pd.DataFrame(Y_a_hat)\n",
    "    yhb = pd.DataFrame(Y_b_hat)\n",
    "\n",
    "    SE_A = ((yi - yha) ** 2)\n",
    "    MSE_A = SE_A.mean()\n",
    "    RMSE_A = MSE_A ** 0.5\n",
    "\n",
    "    SE_B = ((yi - yhb) ** 2)\n",
    "    MSE_B = SE_B.mean()\n",
    "    RMSE_B = MSE_B ** 0.5\n",
    "\n",
    "\n",
    "    treat_a_estimates += [res_a.params['treat']]\n",
    "    treat_b_estimates += [res_b.params['treat']]\n",
    "\n",
    "    RMSE_A_3 += [RMSE_A]\n",
    "    RMSE_B_3 += [RMSE_B]\n",
    "    \n",
    "    \n",
    "#Final results --- avg. over 1000 Monte Carlo Simulations\n",
    "\n",
    "miua = round(np.mean(treat_a_estimates),3)\n",
    "miub = round(np.mean(treat_b_estimates),3)\n",
    "\n",
    "bias_a = round(miua - d,3)\n",
    "bias_b = round(miub - d,3)\n",
    "\n",
    "miu_ra = round(np.mean(RMSE_A_3),3)\n",
    "miu_rb = round(np.mean(RMSE_B_3),3)\n",
    "\n",
    "\n",
    "print(\"Treatment effect in situation A, controlling for path variable is: \" + str(miua) + \" with a bias of \" + str(bias_a) + '.')\n",
    "print('\\n')\n",
    "print(\"Treatment effect in situation B, not controlling for path variable is: \" + str(miub) + \" with a bias of \" + str(bias_b) + '.')\n",
    "print('\\n')\n",
    "print(\"As we see, omitting path variable will lead to bias in coefficient estimates.\")\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print(\"RMSE in situation A, controlling for covariates is: \" + str(miu_ra) + '.')\n",
    "print('\\n')\n",
    "print(\"RMSE in situation B, not controlling for covariates is: \" + str(miu_rb) + '.')\n",
    "print('\\n')\n",
    "print(\"We also see that omitting confounder will lead to higher RMSE.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da979735",
   "metadata": {},
   "source": [
    "A real life example of this setting 3 for selection bias involves any treatment that faces a selection process that may possess inherently bias characteristics in determining some outcome of interest. For example, if we wish to test the effectiveness on some vitamin supplements on overall health. The problem is that there is a selection bias, or a variable in the path from the cause to the effect because it is likely that healthy people will not be in the market for vitamin supplements. Thus, the sample population is likely to be skewed towards being unhealthy, this could mean that the estimated effect of the vitamins may be overestimated or underestimated depending on the scenario. Unhealthy people could see a larger effect due to having more area of improvement, or unhealthy people could see a smaller effect due to unhealthy bodies less likely to adapt healthy ways..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59d11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
